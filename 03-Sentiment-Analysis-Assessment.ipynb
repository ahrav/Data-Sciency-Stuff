{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Assessment - Solution\n",
    "\n",
    "## Task #1: Perform vector arithmetic on your own words\n",
    "Write code that evaluates vector arithmetic on your own set of related words. The goal is to come as close to an expected word as possible. Please feel free to share success stories in the Q&A Forum for this section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library. Remember to use a larger model!\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car car 1.0\n",
      "car , 0.23315491\n",
      "car far 0.32341847\n",
      "car , 0.23315491\n",
      "car bar 0.25503626\n",
      "car , 0.23315491\n",
      "car bike 0.53577304\n",
      "car , 0.23315491\n",
      "car fat 0.18859658\n",
      "car , 0.23315491\n",
      "car close 0.32951674\n",
      "car , 0.23315491\n",
      "car meter 0.23412938\n",
      "car , 0.23315491\n",
      "car philosophy 0.102659844\n",
      ", car 0.23315491\n",
      ", , 1.0\n",
      ", far 0.33760205\n",
      ", , 1.0\n",
      ", bar 0.19794135\n",
      ", , 1.0\n",
      ", bike 0.15927085\n",
      ", , 1.0\n",
      ", fat 0.1680103\n",
      ", , 1.0\n",
      ", close 0.21540403\n",
      ", , 1.0\n",
      ", meter 0.0988956\n",
      ", , 1.0\n",
      ", philosophy 0.16384633\n",
      "far car 0.32341847\n",
      "far , 0.33760205\n",
      "far far 1.0\n",
      "far , 0.33760205\n",
      "far bar 0.2636758\n",
      "far , 0.33760205\n",
      "far bike 0.32935345\n",
      "far , 0.33760205\n",
      "far fat 0.28698316\n",
      "far , 0.33760205\n",
      "far close 0.6202715\n",
      "far , 0.33760205\n",
      "far meter 0.22008328\n",
      "far , 0.33760205\n",
      "far philosophy 0.34698805\n",
      ", car 0.23315491\n",
      ", , 1.0\n",
      ", far 0.33760205\n",
      ", , 1.0\n",
      ", bar 0.19794135\n",
      ", , 1.0\n",
      ", bike 0.15927085\n",
      ", , 1.0\n",
      ", fat 0.1680103\n",
      ", , 1.0\n",
      ", close 0.21540403\n",
      ", , 1.0\n",
      ", meter 0.0988956\n",
      ", , 1.0\n",
      ", philosophy 0.16384633\n",
      "bar car 0.25503626\n",
      "bar , 0.19794135\n",
      "bar far 0.2636758\n",
      "bar , 0.19794135\n",
      "bar bar 1.0\n",
      "bar , 0.19794135\n",
      "bar bike 0.30509454\n",
      "bar , 0.19794135\n",
      "bar fat 0.24801712\n",
      "bar , 0.19794135\n",
      "bar close 0.34292662\n",
      "bar , 0.19794135\n",
      "bar meter 0.28758815\n",
      "bar , 0.19794135\n",
      "bar philosophy 0.111012995\n",
      ", car 0.23315491\n",
      ", , 1.0\n",
      ", far 0.33760205\n",
      ", , 1.0\n",
      ", bar 0.19794135\n",
      ", , 1.0\n",
      ", bike 0.15927085\n",
      ", , 1.0\n",
      ", fat 0.1680103\n",
      ", , 1.0\n",
      ", close 0.21540403\n",
      ", , 1.0\n",
      ", meter 0.0988956\n",
      ", , 1.0\n",
      ", philosophy 0.16384633\n",
      "bike car 0.53577304\n",
      "bike , 0.15927085\n",
      "bike far 0.32935345\n",
      "bike , 0.15927085\n",
      "bike bar 0.30509454\n",
      "bike , 0.15927085\n",
      "bike bike 1.0\n",
      "bike , 0.15927085\n",
      "bike fat 0.24105442\n",
      "bike , 0.15927085\n",
      "bike close 0.26140466\n",
      "bike , 0.15927085\n",
      "bike meter 0.25617832\n",
      "bike , 0.15927085\n",
      "bike philosophy 0.11514761\n",
      ", car 0.23315491\n",
      ", , 1.0\n",
      ", far 0.33760205\n",
      ", , 1.0\n",
      ", bar 0.19794135\n",
      ", , 1.0\n",
      ", bike 0.15927085\n",
      ", , 1.0\n",
      ", fat 0.1680103\n",
      ", , 1.0\n",
      ", close 0.21540403\n",
      ", , 1.0\n",
      ", meter 0.0988956\n",
      ", , 1.0\n",
      ", philosophy 0.16384633\n",
      "fat car 0.18859658\n",
      "fat , 0.1680103\n",
      "fat far 0.28698316\n",
      "fat , 0.1680103\n",
      "fat bar 0.24801712\n",
      "fat , 0.1680103\n",
      "fat bike 0.24105442\n",
      "fat , 0.1680103\n",
      "fat fat 1.0\n",
      "fat , 0.1680103\n",
      "fat close 0.18879804\n",
      "fat , 0.1680103\n",
      "fat meter 0.12290638\n",
      "fat , 0.1680103\n",
      "fat philosophy 0.11340967\n",
      ", car 0.23315491\n",
      ", , 1.0\n",
      ", far 0.33760205\n",
      ", , 1.0\n",
      ", bar 0.19794135\n",
      ", , 1.0\n",
      ", bike 0.15927085\n",
      ", , 1.0\n",
      ", fat 0.1680103\n",
      ", , 1.0\n",
      ", close 0.21540403\n",
      ", , 1.0\n",
      ", meter 0.0988956\n",
      ", , 1.0\n",
      ", philosophy 0.16384633\n",
      "close car 0.32951674\n",
      "close , 0.21540403\n",
      "close far 0.6202715\n",
      "close , 0.21540403\n",
      "close bar 0.34292662\n",
      "close , 0.21540403\n",
      "close bike 0.26140466\n",
      "close , 0.21540403\n",
      "close fat 0.18879804\n",
      "close , 0.21540403\n",
      "close close 1.0\n",
      "close , 0.21540403\n",
      "close meter 0.20229158\n",
      "close , 0.21540403\n",
      "close philosophy 0.1778315\n",
      ", car 0.23315491\n",
      ", , 1.0\n",
      ", far 0.33760205\n",
      ", , 1.0\n",
      ", bar 0.19794135\n",
      ", , 1.0\n",
      ", bike 0.15927085\n",
      ", , 1.0\n",
      ", fat 0.1680103\n",
      ", , 1.0\n",
      ", close 0.21540403\n",
      ", , 1.0\n",
      ", meter 0.0988956\n",
      ", , 1.0\n",
      ", philosophy 0.16384633\n",
      "meter car 0.23412938\n",
      "meter , 0.0988956\n",
      "meter far 0.22008328\n",
      "meter , 0.0988956\n",
      "meter bar 0.28758815\n",
      "meter , 0.0988956\n",
      "meter bike 0.25617832\n",
      "meter , 0.0988956\n",
      "meter fat 0.12290638\n",
      "meter , 0.0988956\n",
      "meter close 0.20229158\n",
      "meter , 0.0988956\n",
      "meter meter 1.0\n",
      "meter , 0.0988956\n",
      "meter philosophy 0.0021667317\n",
      ", car 0.23315491\n",
      ", , 1.0\n",
      ", far 0.33760205\n",
      ", , 1.0\n",
      ", bar 0.19794135\n",
      ", , 1.0\n",
      ", bike 0.15927085\n",
      ", , 1.0\n",
      ", fat 0.1680103\n",
      ", , 1.0\n",
      ", close 0.21540403\n",
      ", , 1.0\n",
      ", meter 0.0988956\n",
      ", , 1.0\n",
      ", philosophy 0.16384633\n",
      "philosophy car 0.102659844\n",
      "philosophy , 0.16384633\n",
      "philosophy far 0.34698805\n",
      "philosophy , 0.16384633\n",
      "philosophy bar 0.111012995\n",
      "philosophy , 0.16384633\n",
      "philosophy bike 0.11514761\n",
      "philosophy , 0.16384633\n",
      "philosophy fat 0.11340967\n",
      "philosophy , 0.16384633\n",
      "philosophy close 0.1778315\n",
      "philosophy , 0.16384633\n",
      "philosophy meter 0.0021667317\n",
      "philosophy , 0.16384633\n",
      "philosophy philosophy 1.0\n"
     ]
    }
   ],
   "source": [
    "# Choose the words you wish to compare, and obtain their vectors\n",
    "tokens = nlp(u'car, far, bar, bike, fat, close, meter, philosophy')\n",
    "\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spatial and define a cosine_similarity function\n",
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda x,y: 1 - spatial.distance.cosine(x,y)\n",
    "\n",
    "cow = nlp.vocab['cow'].vector\n",
    "milk = nlp.vocab['milk'].vector\n",
    "beef = nlp.vocab['beef'].vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an expression for vector arithmetic\n",
    "# For example: new_vector = word1 - word2 + word3\n",
    "new_vector = cow - milk + beef\n",
    "computed_similarities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beef', 'cow', 'pork', 'pig', 'hog', 'lamb', 'meat', 'steak', 'cattle', 'venison']\n"
     ]
    }
   ],
   "source": [
    "# List the top ten closest vectors in the vocabulary to the result of the expression above\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector and word.is_lower and word.is_alpha:\n",
    "        similarity = cosine_similarity(new_vector, word.vector)\n",
    "        computed_similarities.append((word, similarity))\n",
    "\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "\n",
    "\n",
    "print([w[0].text for w in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHALLENGE: Write a function that takes in 3 strings, performs a-b+c arithmetic, and returns a top-ten result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def vector_math():\n",
    "    computed_similarities = []\n",
    "    def compute(a,b,c):\n",
    "        nonlocal computed_similarities\n",
    "        if len(computed_similarities) == 0:\n",
    "            a = nlp.vocab[a].vector\n",
    "            b = nlp.vocab[b].vector\n",
    "            c = nlp.vocab[c].vector\n",
    "\n",
    "            new_vector = a - b + c\n",
    "\n",
    "\n",
    "            for word in nlp.vocab:\n",
    "                if word.has_vector and word.is_lower and word.is_alpha:\n",
    "                    similarity = cosine_similarity(new_vector, word.vector)\n",
    "                    computed_similarities.append((word, similarity))\n",
    "\n",
    "            computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "            return computed_similarities[random.randint(0,5)][0].text\n",
    "        return computed_similarities[random.randint(0,5)][0].text\n",
    "    return compute\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function on known words:\n",
    "v = vector_math()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'king'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v('king','man','woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task #2: Perform VADER Sentiment Analysis on your own review\n",
    "Write code that returns a set of SentimentIntensityAnalyzer polarity scores based on your own written review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SentimentIntensityAnalyzer and create an sid object\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a review as one continuous string (multiple sentences are ok)\n",
    "review = 'GREATTTTT AMAZING SUPER AWESOME!!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.073, 'pos': 0.927, 'compound': 0.9284}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the sid scores for your review\n",
    "sid.polarity_scores(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHALLENGE: Write a function that takes in a review and returns a score of \"Positive\", \"Negative\" or \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_rating(string):\n",
    "    ratings = sid.polarity_scores(string)['compound']\n",
    "    if ratings > 0:\n",
    "        return 'Positive'\n",
    "    elif ratings < 0:\n",
    "        return 'Negative'\n",
    "    return 'Neutral'\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function on your review above:\n",
    "review_rating(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
